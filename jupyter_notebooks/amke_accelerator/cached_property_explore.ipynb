{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b83922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "from functools import cached_property\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0326f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['Sums', 'UserDataCfg', 'c_piranha', 'crix_w8', 'det_crix_w8', 'det_rix_fim0', 'det_rix_fim1', 'epics_archiver', 'intg', 'lightStatus', 'mono_hrencoder', 'rix_fim0', 'rix_fim1', 'scan', 'timestamp', 'timing']>\n"
     ]
    }
   ],
   "source": [
    "pathobj = Path(\"amke_testfile.h5\").resolve()\n",
    "with h5py.File(pathobj) as h5f:\n",
    "    print(h5f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector():\n",
    "\n",
    "    def __init__(self, group: h5py.Group, data_to_read: dict):\n",
    "        # group = first level group, e.g. andordir, data_to_read: lower level data in andor_dir\n",
    "        self.__grp = group\n",
    "        self.prop_factory(data_to_read)\n",
    "\n",
    "    def prop_set(self, data_set):\n",
    "        def fget(self):\n",
    "            return self.__grp[data_set][()]\n",
    "        return fget\n",
    "\n",
    "\n",
    "    def prop_factory(self, data_to_read: dict):\n",
    "        \"\"\"Set up all the desired cached properties.\"\"\"\n",
    "        for name, dataset in data_to_read.items():\n",
    "            prop=cached_property(self.prop_set(dataset))\n",
    "            setattr(self.__class__, name,prop)\n",
    "            prop.__set_name__(self.__class__, name)\n",
    "\n",
    "andor_dir_dict = {\n",
    "    'count': 'count',\n",
    "    'full_area': 'full_area',\n",
    "    'eventcodes': 'timing_sum_eventcodes',\n",
    "    'apds': 'det_crix_w8_sum_full_area',\n",
    "    'fim_0': 'det_rix_fim0_sum_full_area',\n",
    "    'fim_1': 'det_rix_fim1_sum_full_area',\n",
    "    'mono_encoder': 'mono_hrencoder_sum_value',\n",
    "    'piranha': 'c_piranha_sum_full_area'}\n",
    "andor_vls_dict = andor_dir_dict # assuming both detectors have the same keys\n",
    "\n",
    "axis_svls_dict = {\n",
    "    'count': 'count',\n",
    "    'full_area': 'full_area',\n",
    "}\n",
    "\n",
    "detectors = {\n",
    "    'andor_dir': {'attrdict': andor_dir_dict, 'clsname': 'AndorDir'},\n",
    "    'andor_vls': {'attrdict': andor_vls_dict, 'clsname': 'AndorVLS'},\n",
    "    'axis_svls': {'attrdict': axis_svls_dict, 'clsname': 'AxisSVLS'},\n",
    "}\n",
    "\n",
    "\n",
    "class Integrating():\n",
    "\n",
    "    \"\"\"\n",
    "    Class for accessing all data related to \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, intgrp: h5py.Group):\n",
    "        for detector in detectors:\n",
    "            if detector in intgrp.keys():\n",
    "                detobj = type(detectors[detector][\"clsname\"], (Detector,), {})\n",
    "                setattr(self, detector, detobj(intgrp[detector], detectors[detector]['attrdict']))\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name in detectors:\n",
    "            raise KeyError(f\"{name} not in this file.\")\n",
    "        return super().__getattribute__(name)\n",
    "\n",
    "class Singleshot():\n",
    "\n",
    "    def __init__(self, ssgrp: h5py.Group):\n",
    "        grp = ssgrp \n",
    "        Piranha = type(\"Piranha\", (Detector,), {})\n",
    "        self.piranha = Piranha(grp, {\"piranha\": \"c_piranha\"})\n",
    "\n",
    "class SmallData():\n",
    "    \"\"\"\n",
    "    A  class for fast read-only interface to our small data files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str or Path or h5py File or Group object\n",
    "        The filename to read from.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path: str | Path | h5py.File | h5py.Group):\n",
    "        self.__file = None\n",
    "        if isinstance(path, h5py.File):\n",
    "            self.path = Path(path.filename).resolve()\n",
    "            self.__file = path\n",
    "        elif isinstance(path, h5py.Group):\n",
    "            self.path = Path(path.file.filename).resolve()\n",
    "            self.__file = path.file\n",
    "        elif isinstance(path, str | Path):\n",
    "            self.path = Path(path).resolve()\n",
    "     \n",
    "    def is_open(self) -> bool:\n",
    "        \"\"\"Whether the file is open.\"\"\"\n",
    "        return bool(self.__file)\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Close the file when the object is deleted.\"\"\"\n",
    "        if self.__file:\n",
    "            self.__file.close()\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the file.\"\"\"\n",
    "        self.integrating = None\n",
    "\n",
    "        with contextlib.suppress(AttributeError):\n",
    "            del self.__intgrp\n",
    "\n",
    "        if self.__file:\n",
    "            self.__file.close()\n",
    "        self.__file = None\n",
    "\n",
    "    def open(self):  # noqa: A003\n",
    "        \"\"\"Open the file.\"\"\"\n",
    "        if not self.__file:\n",
    "            self.__file = h5py.File(self.path, \"r\")\n",
    "            self.__intgrp = self.__file[\"/intg\"]\n",
    "            self.__ssgrp = self.__file[\"/\"]\n",
    "\n",
    "    @cached_property\n",
    "    def integrating(self) -> h5py.Group:\n",
    "        \"\"\"Get the integrating object.\"\"\"\n",
    "        if not self.__file:\n",
    "            self.open()\n",
    "        return Integrating(self.__intgrp)\n",
    "\n",
    "    @cached_property\n",
    "    def single_shot(self) -> h5py.Group:\n",
    "        \"\"\"Get the integrating object.\"\"\"\n",
    "        if not self.__file:\n",
    "            self.open()\n",
    "        return Singleshot(self.__ssgrp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ad4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "smdata = SmallData(pathobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e337cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "andor = smdata.integrating.andor_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4259dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "andor.apds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f65c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Piranha at 0x10e09c6e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smdata.single_shot.piranha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d702786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
